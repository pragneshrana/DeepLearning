{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Import Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"Training Data.csv\")\n",
    "test = pd.read_csv(\"Test Data.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(221004, 13)\n",
      "(30996, 13)\n"
     ]
    }
   ],
   "source": [
    "train_zero = train[train['risk_flag'] == 0]\n",
    "train_ones = train[train['risk_flag'] == 1]\n",
    "\n",
    "print(train_zero.shape)\n",
    "print(train_ones.shape)\n",
    "\n",
    "train_data = pd.concat([train_zero.sample(30996),train_ones.sample(30996)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check how train dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>experience</th>\n",
       "      <th>married</th>\n",
       "      <th>house_ownership</th>\n",
       "      <th>car_ownership</th>\n",
       "      <th>profession</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>current_job_years</th>\n",
       "      <th>current_house_years</th>\n",
       "      <th>risk_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1303835</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Mechanical_engineer</td>\n",
       "      <td>Rewa</td>\n",
       "      <td>Madhya_Pradesh</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7574516</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Software_Developer</td>\n",
       "      <td>Parbhani</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3991815</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>married</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Technical_writer</td>\n",
       "      <td>Alappuzha</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6256451</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>yes</td>\n",
       "      <td>Software_Developer</td>\n",
       "      <td>Bhubaneswar</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5768871</td>\n",
       "      <td>47</td>\n",
       "      <td>11</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Civil_servant</td>\n",
       "      <td>Tiruchirappalli[10]</td>\n",
       "      <td>Tamil_Nadu</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   income  age  experience  married house_ownership car_ownership  \\\n",
       "0   1  1303835   23           3   single          rented            no   \n",
       "1   2  7574516   40          10   single          rented            no   \n",
       "2   3  3991815   66           4  married          rented            no   \n",
       "3   4  6256451   41           2   single          rented           yes   \n",
       "4   5  5768871   47          11   single          rented            no   \n",
       "\n",
       "            profession                 city           state  \\\n",
       "0  Mechanical_engineer                 Rewa  Madhya_Pradesh   \n",
       "1   Software_Developer             Parbhani     Maharashtra   \n",
       "2     Technical_writer            Alappuzha          Kerala   \n",
       "3   Software_Developer          Bhubaneswar          Odisha   \n",
       "4        Civil_servant  Tiruchirappalli[10]      Tamil_Nadu   \n",
       "\n",
       "   current_job_years  current_house_years  risk_flag  \n",
       "0                  3                   13          0  \n",
       "1                  9                   13          0  \n",
       "2                  4                   10          0  \n",
       "3                  2                   12          1  \n",
       "4                  3                   14          1  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61992, 13)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>experience</th>\n",
       "      <th>married</th>\n",
       "      <th>house_ownership</th>\n",
       "      <th>car_ownership</th>\n",
       "      <th>profession</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>current_job_years</th>\n",
       "      <th>current_house_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7393090</td>\n",
       "      <td>59</td>\n",
       "      <td>19</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Geologist</td>\n",
       "      <td>Malda</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1215004</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Firefighter</td>\n",
       "      <td>Jalna</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8901342</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>Thane</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1944421</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "      <td>married</td>\n",
       "      <td>rented</td>\n",
       "      <td>yes</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Latur</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13429</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>yes</td>\n",
       "      <td>Comedian</td>\n",
       "      <td>Berhampore</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   income  age  experience  married house_ownership car_ownership  \\\n",
       "0   1  7393090   59          19   single          rented            no   \n",
       "1   2  1215004   25           5   single          rented            no   \n",
       "2   3  8901342   50          12   single          rented            no   \n",
       "3   4  1944421   49           9  married          rented           yes   \n",
       "4   5    13429   25          18   single          rented           yes   \n",
       "\n",
       "    profession        city        state  current_job_years  \\\n",
       "0    Geologist       Malda  West Bengal                  4   \n",
       "1  Firefighter       Jalna  Maharashtra                  5   \n",
       "2       Lawyer       Thane  Maharashtra                  9   \n",
       "3      Analyst       Latur  Maharashtra                  3   \n",
       "4     Comedian  Berhampore  West Bengal                 13   \n",
       "\n",
       "   current_house_years  \n",
       "0                   13  \n",
       "1                   10  \n",
       "2                   14  \n",
       "3                   12  \n",
       "4                   11  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 12)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert datatype of selected fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data(data):\n",
    "    data = data.drop(columns=['Id'],axis=1)\n",
    "    data = data.drop(columns=['state'],axis=1)\n",
    "    data = data.drop(columns=['city'],axis=1)\n",
    "    data = data.drop(columns=['profession'],axis=1)\n",
    "\n",
    "#     data[\"profession\"],unique_profession =pd.factorize(data.profession)\n",
    "#     data[\"city\"],unique_city=pd.factorize(data.city)\n",
    "#     data[\"state\"],unique_state=pd.factorize(data.state)\n",
    "    data[\"married\"],unique_married=pd.factorize(data.married)\n",
    "    data[\"house_ownership\"],unique_house_ownership =pd.factorize(data.house_ownership)\n",
    "    data[\"car_ownership\"],unique_car_ownership=pd.factorize(data.car_ownership)\n",
    "    return data#,unique_profession,unique_city,unique_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data,train_profession,train_city,train_state = convert_data(train_data)\n",
    "train_data = convert_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_data)\n",
    "# print(train_profession)\n",
    "# print(train_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.rename(columns={\"id\": \"Id\"})\n",
    "# test_data,test_profession,test_city,test_state = convert_data(test_data)\n",
    "test_data = convert_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_data)\n",
    "# print(test_profession)\n",
    "# print(test_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop the dependent variable from the train dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=train_data.drop(\"risk_flag\",axis=1)\n",
    "ytrain=train_data[\"risk_flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61992,)\n",
      "30996\n"
     ]
    }
   ],
   "source": [
    "print(ytrain.shape)\n",
    "print(ytrain.isin([0]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_val  = sc.transform(X_val)\n",
    "test_data  = sc.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Keras and Implementation of ANN\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# from keras.models import Sequential #to initialize the NN\n",
    "# from keras.layers import  Dense #to generate the layers\n",
    "# from keras import dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a model defined with the sequential api\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "\n",
    "#Parameter Tuning \n",
    "#Evaluation of ANN by k fold cross validaion\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# def build_classifier(optimizer):\n",
    "#     '''\n",
    "#     LOCAL CLASSIFIER\n",
    "#     for cross validation K times going to call this function \n",
    "#     and it will return \n",
    "#     '''\n",
    "#     # define the model\n",
    "#     model = Sequential()\n",
    "\n",
    "#     #First hidden layer\n",
    "#     #sigmoid for output layer \n",
    "#     #Rectifier for Hidden layer\n",
    "#     model.add(Dense(kernel_initializer=\"uniform\", activation=\"relu\", input_dim=11, units=8))\n",
    "\n",
    "#     #how many nodes? No rules but (avg of number nodes input and output layer) #input+output/2  =(11+1)/2 = 6\n",
    "#     #init  = initilizatin of values\n",
    "\n",
    "#     #second hidden layer \n",
    "#     model.add(Dropout(0.1)) #to avoid overfitting #start with low value if ovefitting doesn't reduce do ovefitting\n",
    "#     model.add(Dense(units=10, activation=\"relu\", kernel_initializer=\"uniform\")) #netwrok knows how to connect so need of input_dim\n",
    "\n",
    "#     #second hidden layer \n",
    "#     model.add(Dropout(0.1)) #to avoid overfitting #start with low value if ovefitting doesn't reduce do ovefitting\n",
    "#     model.add(Dense(units=7, activation=\"relu\", kernel_initializer=\"uniform\")) #netwrok knows how to connect so need of input_dim\n",
    "\n",
    "#     #second hidden layer \n",
    "#     model.add(Dropout(0.1)) #to avoid overfitting #start with low value if ovefitting doesn't reduce do ovefitting\n",
    "#     model.add(Dense(units=4, activation=\"relu\", kernel_initializer=\"uniform\")) #netwrok knows how to connect so need of input_dim\n",
    "\n",
    "\n",
    "#     #Add final-output layer\n",
    "#     model.add(Dropout(0.1))  #to avoid overfitting\n",
    "#     model.add(Dense(units=1, activation=\"sigmoid\", kernel_initializer=\"uniform\")) #netwrok knows how to connect so need of input_dim\n",
    "\n",
    "#     #compile the ANN\n",
    "#     model.compile(optimizer =optimizer, loss ='binary_crossentropy',metrics = ['accuracy'])\n",
    "#     #adam is stochastic gradient method\n",
    "   \n",
    "#     return model\n",
    "\n",
    "# model = KerasClassifier(build_fn=build_classifier)\n",
    "\n",
    "# parameters = {'batch_size' :[100,200,500],\n",
    "#               'nb_epoch' : [10,20,50],\n",
    "#               'optimizer' : ['adam','rmsprop']}\n",
    "\n",
    "# #created object\n",
    "# grid_search = GridSearchCV(estimator = model,\n",
    "#                            param_grid = parameters,\n",
    "#                            scoring = 'accuracy',\n",
    "#                            cv = 2) \n",
    "\n",
    "# #fitting object\n",
    "# grid_search = grid_search.fit(X_train,y_train)\n",
    "# best_parameter =  grid_search.best_params_\n",
    "# best_accuracy  =  grid_search.best_score_\n",
    "        \n",
    "# print(best_parameter)\n",
    "\n",
    "# print(best_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pragnesh/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/pragnesh/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/pragnesh/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 55792 samples\n",
      "Epoch 1/200\n",
      "55792/55792 [==============================] - 7s 132us/sample - loss: 0.6926 - acc: 0.5191\n",
      "Epoch 2/200\n",
      "55792/55792 [==============================] - 6s 106us/sample - loss: 0.6908 - acc: 0.5307\n",
      "Epoch 3/200\n",
      "55792/55792 [==============================] - 6s 104us/sample - loss: 0.6895 - acc: 0.5325\n",
      "Epoch 4/200\n",
      "55792/55792 [==============================] - 5s 88us/sample - loss: 0.6880 - acc: 0.5413\n",
      "Epoch 5/200\n",
      "55792/55792 [==============================] - 4s 79us/sample - loss: 0.6870 - acc: 0.5457\n",
      "Epoch 6/200\n",
      "55792/55792 [==============================] - 4s 68us/sample - loss: 0.6859 - acc: 0.5488\n",
      "Epoch 7/200\n",
      "55792/55792 [==============================] - 4s 68us/sample - loss: 0.6843 - acc: 0.5507\n",
      "Epoch 8/200\n",
      "55792/55792 [==============================] - 4s 63us/sample - loss: 0.6824 - acc: 0.5573\n",
      "Epoch 9/200\n",
      "55792/55792 [==============================] - 4s 67us/sample - loss: 0.6819 - acc: 0.5595\n",
      "Epoch 10/200\n",
      "55792/55792 [==============================] - 4s 66us/sample - loss: 0.6789 - acc: 0.5651\n",
      "Epoch 11/200\n",
      "55792/55792 [==============================] - 4s 65us/sample - loss: 0.6765 - acc: 0.5692\n",
      "Epoch 12/200\n",
      "24000/55792 [===========>..................] - ETA: 2s - loss: 0.6719 - acc: 0.5784"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-e0ae2e55ef63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m#Fit model to training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;31m# 3. Update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# 4. num of epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "\n",
    "#First hidden layer\n",
    "#sigmoid for output layer \n",
    "#Rectifier for Hidden layer\n",
    "model.add(Dense(kernel_initializer=\"uniform\", activation=\"relu\", input_dim=10, units=300))\n",
    "\n",
    "#how many nodes? No rules but (avg of number nodes input and output layer) #input+output/2  =(11+1)/2 = 6\n",
    "#init  = initilizatin of values\n",
    "\n",
    "#second hidden layer \n",
    "model.add(Dropout(0.1)) #to avoid overfitting #start with low value if ovefitting doesn't reduce do ovefitting\n",
    "model.add(Dense(units=500, activation=\"relu\", kernel_initializer=\"uniform\")) #netwrok knows how to connect so need of input_dim\n",
    "\n",
    "#third hidden layer \n",
    "model.add(Dropout(0.1)) #to avoid overfitting #start with low value if ovefitting doesn't reduce do ovefitting\n",
    "model.add(Dense(units=300, activation=\"relu\", kernel_initializer=\"uniform\")) #netwrok knows how to connect so need of input_dim\n",
    "\n",
    "#fourth hidden layer \n",
    "model.add(Dropout(0.1)) #to avoid overfitting #start with low value if ovefitting doesn't reduce do ovefitting\n",
    "model.add(Dense(units=100, activation=\"relu\", kernel_initializer=\"uniform\")) #netwrok knows how to connect so need of input_dim\n",
    "\n",
    "#fifth hidden layer \n",
    "model.add(Dropout(0.1)) #to avoid overfitting #start with low value if ovefitting doesn't reduce do ovefitting\n",
    "model.add(Dense(units=20, activation=\"relu\", kernel_initializer=\"uniform\")) #netwrok knows how to connect so need of input_dim\n",
    "\n",
    "#Add final-output layer\n",
    "model.add(Dropout(0.1))  #to avoid overfitting\n",
    "model.add(Dense(units=1, activation=\"sigmoid\", kernel_initializer=\"uniform\")) #netwrok knows how to connect so need of input_dim\n",
    "\n",
    "#compile the ANN\n",
    "model.compile(optimizer='adam', loss ='binary_crossentropy',metrics = ['accuracy'])\n",
    "#adam is stochastic gradient method\n",
    "    \n",
    "#Fit model to training set\n",
    "model.fit(X_train,y_train,batch_size =1000,epochs =200)\n",
    "# 3. Update weights \n",
    "# 4. num of epochs                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicction\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_train = (y_pred_train > 0.5)\n",
    "print(y_pred_train)\n",
    "\n",
    "#Making the confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_train,y_pred_train)\n",
    "print(cm)\n",
    "\n",
    "#Accuracy \n",
    "print(accuracy_score(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicction\n",
    "y_pred_val = model.predict(X_val)\n",
    "y_pred_val = (y_pred_val > 0.5)\n",
    "\n",
    "#Making the confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_val,y_pred_val)\n",
    "print(cm)\n",
    "\n",
    "#Accuracy \n",
    "print(accuracy_score(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on test_data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred > 0.5)\n",
    "res = pd.DataFrame([])\n",
    "res[\"id\"] = test[\"Id\"].copy()\n",
    "res[\"risk_flag\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res #result\n",
    "res.to_csv('result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_zero = res[res['risk_flag'] == 0]\n",
    "res_ones = res[res['risk_flag'] == 1]\n",
    "print(res_zero.shape)\n",
    "print(res_ones.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
