{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_CNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOQwaqwISPzXm3ujf43UOMs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pragneshrana/DeepLearning/blob/master/CNN/MNIST_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTLOE-wfxlHe",
        "colab_type": "text"
      },
      "source": [
        "* Instead of CIFAR10, use the MNIST data available from `torchvision.datasets.MNIST`. Download and visualise MNIST data.\n",
        "* But importantly MNIST images have only 1 channel instead of 3 channels in the case of CIFAR10. Modify LeNet to work with MNIST. Train and find optimised test accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebTDFe6qZOS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3RZSgGLO9iY",
        "colab_type": "text"
      },
      "source": [
        "## Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOgFtnl2ZXsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, \n",
        "                                        download=True, \n",
        "                                        transform=transforms.ToTensor())"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpU3_h-JaFi_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGkggskRaXhz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "57dab428-248b-440f-e3a0-ef4a2f1a2b28"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "print(images.shape)\n",
        "\n",
        "print(images[1].shape)\n",
        "print(labels[1].item())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 1, 28, 28])\n",
            "torch.Size([1, 28, 28])\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOQGdybZRQqk",
        "colab_type": "text"
      },
      "source": [
        "## Training LeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylTZodUuV1eb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self): \n",
        "        super(LeNet, self).__init__()\n",
        "        self.cnn_model = nn.Sequential(\n",
        "            nn.Conv2d(1, 20, 5),         # (N, 1, 28, 28) -> (N,  20, 24, 24)\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(2, stride=2),  # (N, 20, 24, 24) -> (N,  20, 12, 12)\n",
        "            nn.Conv2d(20, 40, 3),        # (N, 20, 12, 12) -> (N, 40, 10, 10)  \n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(40, 10, 3),        # (N, 40, 10, 10) -> (N, 10, 8, 8)  \n",
        "        )\n",
        "        self.fc_model = nn.Sequential(\n",
        "            nn.Linear(640,400),         # (N, 640) -> (N, 400) 10*8*8 = 640\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(400,120),         # (N, 400) -> (N, 120) \n",
        "            nn.ReLU(),\n",
        "            nn.Linear(120,84),          # (N, 120) -> (N, 84)\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(84,10)            # (N, 84)  -> (N, 10)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.cnn_model(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc_model(x)\n",
        "        return x"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOWc4kya8UDC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pYTvSvD2TwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = LeNet()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T6Wzz7J2xq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt = optim.Adam(net.parameters(),)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECHeB_BUTHl5",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Move to GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj0-Y6zJTJ5z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "19f07ef0-03c1-483f-f7b2-6e1d64f6cfab"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4fHbz2fTNpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluation(dataloader):\n",
        "    total, correct = 0, 0\n",
        "    for data in dataloader:\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = net(inputs)\n",
        "        _, pred = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (pred == labels).sum().item()\n",
        "    return 100 * correct / total"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnxecsfVTQH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = LeNet().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt = optim.Adam(net.parameters())"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9t3Js-XTWkf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 968
        },
        "outputId": "20d69e59-1215-483b-8c00-0b19d825d0a7"
      },
      "source": [
        "%%time\n",
        "max_epochs = 50\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        opt.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        \n",
        "    print('Epoch: %d/%d' % (epoch, max_epochs))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0/50\n",
            "Epoch: 1/50\n",
            "Epoch: 2/50\n",
            "Epoch: 3/50\n",
            "Epoch: 4/50\n",
            "Epoch: 5/50\n",
            "Epoch: 6/50\n",
            "Epoch: 7/50\n",
            "Epoch: 8/50\n",
            "Epoch: 9/50\n",
            "Epoch: 10/50\n",
            "Epoch: 11/50\n",
            "Epoch: 12/50\n",
            "Epoch: 13/50\n",
            "Epoch: 14/50\n",
            "Epoch: 15/50\n",
            "Epoch: 16/50\n",
            "Epoch: 17/50\n",
            "Epoch: 18/50\n",
            "Epoch: 19/50\n",
            "Epoch: 20/50\n",
            "Epoch: 21/50\n",
            "Epoch: 22/50\n",
            "Epoch: 23/50\n",
            "Epoch: 24/50\n",
            "Epoch: 25/50\n",
            "Epoch: 26/50\n",
            "Epoch: 27/50\n",
            "Epoch: 28/50\n",
            "Epoch: 29/50\n",
            "Epoch: 30/50\n",
            "Epoch: 31/50\n",
            "Epoch: 32/50\n",
            "Epoch: 33/50\n",
            "Epoch: 34/50\n",
            "Epoch: 35/50\n",
            "Epoch: 36/50\n",
            "Epoch: 37/50\n",
            "Epoch: 38/50\n",
            "Epoch: 39/50\n",
            "Epoch: 40/50\n",
            "Epoch: 41/50\n",
            "Epoch: 42/50\n",
            "Epoch: 43/50\n",
            "Epoch: 44/50\n",
            "Epoch: 45/50\n",
            "Epoch: 46/50\n",
            "Epoch: 47/50\n",
            "Epoch: 48/50\n",
            "Epoch: 49/50\n",
            "CPU times: user 6min 53s, sys: 1.98 s, total: 6min 55s\n",
            "Wall time: 6min 57s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mao_iiQZVlE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fc340557-a601-4498-f513-8315965bb182"
      },
      "source": [
        "print('Test acc: %0.2f, Train acc: %0.2f' % (evaluation(testloader), evaluation(trainloader)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test acc: 99.27, Train acc: 99.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWZpK80MCXTR",
        "colab_type": "text"
      },
      "source": [
        "**Was Just playing and got this :)**"
      ]
    }
  ]
}