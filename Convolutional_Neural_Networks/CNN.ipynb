{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pragneshrana/DeepLearning/blob/master/Convolutional_Neural_Networks/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21iB7Cd6Knoq",
        "colab_type": "text"
      },
      "source": [
        "# CNN - Convolution Neural Network\n",
        "COntent : \n",
        "1. Convolution Operation - feature detection, feature map, etc\n",
        "2. ReLU layer \n",
        "3. Pooling - max, min and other pooling \n",
        "4. Flattening \n",
        "5. Full Connection "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRFnPNEiLXW6",
        "colab_type": "text"
      },
      "source": [
        "Brain look at features of the images and classify the data.<br>\n",
        "Black and white images are 2D images(0 to 255 pixels) and colour images are 3D images(RGB).\n",
        "Steps:\n",
        "1. Convolution\n",
        "2. MaxPooling\n",
        "3. Flattening\n",
        "4. Full Connection\n",
        "\n",
        "# 1. What is convolution ?<br>\n",
        "$(f*g)(t) = \\int_{-\\infty}^{\\infty} f(\\tau) g(t-\\tau) d\\tau\n",
        "$ <br>\n",
        "Convolution operation is combined integration of two function and it shows how one function modifies the shape of other function. <br>\n",
        "\n",
        "link : https://cs.nju.edu.cn/wujx/  <br>\n",
        "\n",
        "Feature matrix / kernel / filter  (let's take 3X3) and input image.<br>\n",
        "\n",
        "$$Input \\space image \\otimes \\space feature \\space detector \\space  = feature \\space map$$\n",
        "\n",
        "$$\n",
        "  \\begin{bmatrix}\n",
        "  1 & 2 & 0 \\\\\n",
        "  0 & 3 & 0 \\\\\n",
        "  6 & 2 & 0 \\\\\n",
        "  \\end{bmatrix}\n",
        "  \\otimes\n",
        "  \\begin{bmatrix}\n",
        "  1 & 0 \\\\\n",
        "  0 & 1 \\\\\n",
        "  \\end{bmatrix}\n",
        "  = \n",
        "  \\begin{bmatrix}\n",
        "  4 & 2 \\\\\n",
        "  2 & 3 \\\\\n",
        "  \\end{bmatrix}\n",
        "$$<br>\n",
        "\n",
        "Feature detector matrix rolls over input images step by step(stride-rate at which move on pixel). In each step, **element wise dot product is done and add up the result and feature map / convolved feature is obtained.** <br>\n",
        "\n",
        "**why are doing this?** -> to make image smaller and make opertaion faster.<br>\n",
        "\n",
        "**Are we loosing information ?** -> yes, but we are also trying to getting the integrated information using this.<br>\n",
        "\n",
        "By repeating this procedure we can multiple feature map using different feature detector/filter. <br>\n",
        "like(shapen/blur/edge enhance/**edge detect**/emboss) are example of feature detector.\n",
        "\n",
        "\n",
        "#What is ReLU?\n",
        "Rectified linear unit.<br>\n",
        "$$ \\phi  = max(x,0)$$\n",
        "**Why apply?** --- To increase the non linearity in the convolution network. Images are generally non-linear in edge, colour and features.<br>\n",
        "Generally images have progression in images(gradual change from white to dark) which is kind of linearlity. <br>\n",
        "\n",
        "link : https://arxiv.org/abs/1609.04112  <br>\n",
        "link : https://arxiv.org/abs/1502.01852  <br>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVKr1_JSYqFO",
        "colab_type": "text"
      },
      "source": [
        "# 2.Max Pooling/ Down Sampling\n",
        "Spatial Variacne - irrspecctive where features located NN should be able to detect it. \\\n",
        "$$feature \\space map  \\  \\underrightarrow{\\tiny Max Pooling} \\ Pooled \\ feature \\ map$$<br>\n",
        "$\n",
        "  \\begin{bmatrix}\n",
        "  |1 & 2 |& 0 & 0 & 1\\\\\n",
        "  |0 & 3| & 0 & 0 & 1 \\\\\n",
        "  6 & 2 & 0 & 0 & 1\\\\\n",
        "  1 & 5 & 0 & 0 & 1\\\\\n",
        "  8 & 2 & 0 & 0 & 1\\\\\n",
        "  \\end{bmatrix}\n",
        "   \\underrightarrow{\\tiny Max Pooling}\n",
        "    \\begin{bmatrix}\n",
        "  3 & 0 & 1\\\\\n",
        "  6 & 0 & 1\\\\\n",
        "  8 & 0 & 1\\\\\n",
        "  \\end{bmatrix}\n",
        "$<br>\n",
        "\n",
        " - last line we have cross over means we went out or just took last colm only<br>.\n",
        "\n",
        "- Here we are striding by two means moving by two rows<br>\n",
        "\n",
        "- Take feature map matrix and roll any size of matrix let's(2X2) and out of that just record max value from that rolling matrix <br>\n",
        "\n",
        "- Doing this we have reduce 75% information. <br>\n",
        "- Also accouting the distortion of feature means if highlightes feature are shifted then we are trying to capture those important features<br>\n",
        "- By removing the features or details we are reducing the overfitting.<br>\n",
        "\n",
        "(MUST)link : http://ais.uni-bonn.de/papers/icann2010_maxpool.pdf <br>\n",
        "subsampaling - avg.pooling\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y36LHaLBNcfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}